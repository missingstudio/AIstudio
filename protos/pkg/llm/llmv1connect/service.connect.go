// Code generated by protoc-gen-connect-go. DO NOT EDIT.
//
// Source: llm/service.proto

package llmv1connect

import (
	connect "connectrpc.com/connect"
	context "context"
	errors "errors"
	llm "github.com/missingstudio/studio/protos/pkg/llm"
	emptypb "google.golang.org/protobuf/types/known/emptypb"
	http "net/http"
	strings "strings"
)

// This is a compile-time assertion to ensure that this generated file and the connect package are
// compatible. If you get a compiler error that this constant is not defined, this code was
// generated with a version of connect newer than the one compiled into your binary. You can fix the
// problem by either regenerating this code with an older version of connect or updating the connect
// version compiled into your binary.
const _ = connect.IsAtLeastVersion1_13_0

const (
	// LLMServiceName is the fully-qualified name of the LLMService service.
	LLMServiceName = "llm.v1.LLMService"
)

// These constants are the fully-qualified names of the RPCs defined in this package. They're
// exposed at runtime as Spec.Procedure and as the final two segments of the HTTP route.
//
// Note that these are different from the fully-qualified method names used by
// google.golang.org/protobuf/reflect/protoreflect. To convert from these constants to
// reflection-formatted method names, remove the leading slash and convert the remaining slash to a
// period.
const (
	// LLMServiceChatCompletionsProcedure is the fully-qualified name of the LLMService's
	// ChatCompletions RPC.
	LLMServiceChatCompletionsProcedure = "/llm.v1.LLMService/ChatCompletions"
	// LLMServiceStreamChatCompletionsProcedure is the fully-qualified name of the LLMService's
	// StreamChatCompletions RPC.
	LLMServiceStreamChatCompletionsProcedure = "/llm.v1.LLMService/StreamChatCompletions"
	// LLMServiceListModelsProcedure is the fully-qualified name of the LLMService's ListModels RPC.
	LLMServiceListModelsProcedure = "/llm.v1.LLMService/ListModels"
	// LLMServiceListProvidersProcedure is the fully-qualified name of the LLMService's ListProviders
	// RPC.
	LLMServiceListProvidersProcedure = "/llm.v1.LLMService/ListProviders"
	// LLMServiceCreateProviderProcedure is the fully-qualified name of the LLMService's CreateProvider
	// RPC.
	LLMServiceCreateProviderProcedure = "/llm.v1.LLMService/CreateProvider"
	// LLMServiceGetProviderProcedure is the fully-qualified name of the LLMService's GetProvider RPC.
	LLMServiceGetProviderProcedure = "/llm.v1.LLMService/GetProvider"
	// LLMServiceUpsertProviderProcedure is the fully-qualified name of the LLMService's UpsertProvider
	// RPC.
	LLMServiceUpsertProviderProcedure = "/llm.v1.LLMService/UpsertProvider"
	// LLMServiceDeleteProviderProcedure is the fully-qualified name of the LLMService's DeleteProvider
	// RPC.
	LLMServiceDeleteProviderProcedure = "/llm.v1.LLMService/DeleteProvider"
	// LLMServiceGetProviderConfigProcedure is the fully-qualified name of the LLMService's
	// GetProviderConfig RPC.
	LLMServiceGetProviderConfigProcedure = "/llm.v1.LLMService/GetProviderConfig"
	// LLMServiceListTrackingLogsProcedure is the fully-qualified name of the LLMService's
	// ListTrackingLogs RPC.
	LLMServiceListTrackingLogsProcedure = "/llm.v1.LLMService/ListTrackingLogs"
)

// These variables are the protoreflect.Descriptor objects for the RPCs defined in this package.
var (
	lLMServiceServiceDescriptor                     = llm.File_llm_service_proto.Services().ByName("LLMService")
	lLMServiceChatCompletionsMethodDescriptor       = lLMServiceServiceDescriptor.Methods().ByName("ChatCompletions")
	lLMServiceStreamChatCompletionsMethodDescriptor = lLMServiceServiceDescriptor.Methods().ByName("StreamChatCompletions")
	lLMServiceListModelsMethodDescriptor            = lLMServiceServiceDescriptor.Methods().ByName("ListModels")
	lLMServiceListProvidersMethodDescriptor         = lLMServiceServiceDescriptor.Methods().ByName("ListProviders")
	lLMServiceCreateProviderMethodDescriptor        = lLMServiceServiceDescriptor.Methods().ByName("CreateProvider")
	lLMServiceGetProviderMethodDescriptor           = lLMServiceServiceDescriptor.Methods().ByName("GetProvider")
	lLMServiceUpsertProviderMethodDescriptor        = lLMServiceServiceDescriptor.Methods().ByName("UpsertProvider")
	lLMServiceDeleteProviderMethodDescriptor        = lLMServiceServiceDescriptor.Methods().ByName("DeleteProvider")
	lLMServiceGetProviderConfigMethodDescriptor     = lLMServiceServiceDescriptor.Methods().ByName("GetProviderConfig")
	lLMServiceListTrackingLogsMethodDescriptor      = lLMServiceServiceDescriptor.Methods().ByName("ListTrackingLogs")
)

// LLMServiceClient is a client for the llm.v1.LLMService service.
type LLMServiceClient interface {
	ChatCompletions(context.Context, *connect.Request[llm.ChatCompletionRequest]) (*connect.Response[llm.ChatCompletionResponse], error)
	StreamChatCompletions(context.Context, *connect.Request[llm.ChatCompletionRequest]) (*connect.ServerStreamForClient[llm.ChatCompletionResponse], error)
	ListModels(context.Context, *connect.Request[llm.ModelRequest]) (*connect.Response[llm.ModelResponse], error)
	ListProviders(context.Context, *connect.Request[emptypb.Empty]) (*connect.Response[llm.ProvidersResponse], error)
	CreateProvider(context.Context, *connect.Request[llm.CreateProviderRequest]) (*connect.Response[llm.CreateProviderResponse], error)
	GetProvider(context.Context, *connect.Request[llm.GetProviderRequest]) (*connect.Response[llm.GetProviderResponse], error)
	UpsertProvider(context.Context, *connect.Request[llm.UpdateProviderRequest]) (*connect.Response[llm.UpdateProviderResponse], error)
	DeleteProvider(context.Context, *connect.Request[llm.DeleteProviderRequest]) (*connect.Response[emptypb.Empty], error)
	GetProviderConfig(context.Context, *connect.Request[llm.GetProviderConfigRequest]) (*connect.Response[llm.GetProviderConfigResponse], error)
	ListTrackingLogs(context.Context, *connect.Request[emptypb.Empty]) (*connect.Response[llm.LogResponse], error)
}

// NewLLMServiceClient constructs a client for the llm.v1.LLMService service. By default, it uses
// the Connect protocol with the binary Protobuf Codec, asks for gzipped responses, and sends
// uncompressed requests. To use the gRPC or gRPC-Web protocols, supply the connect.WithGRPC() or
// connect.WithGRPCWeb() options.
//
// The URL supplied here should be the base URL for the Connect or gRPC server (for example,
// http://api.acme.com or https://acme.com/grpc).
func NewLLMServiceClient(httpClient connect.HTTPClient, baseURL string, opts ...connect.ClientOption) LLMServiceClient {
	baseURL = strings.TrimRight(baseURL, "/")
	return &lLMServiceClient{
		chatCompletions: connect.NewClient[llm.ChatCompletionRequest, llm.ChatCompletionResponse](
			httpClient,
			baseURL+LLMServiceChatCompletionsProcedure,
			connect.WithSchema(lLMServiceChatCompletionsMethodDescriptor),
			connect.WithClientOptions(opts...),
		),
		streamChatCompletions: connect.NewClient[llm.ChatCompletionRequest, llm.ChatCompletionResponse](
			httpClient,
			baseURL+LLMServiceStreamChatCompletionsProcedure,
			connect.WithSchema(lLMServiceStreamChatCompletionsMethodDescriptor),
			connect.WithClientOptions(opts...),
		),
		listModels: connect.NewClient[llm.ModelRequest, llm.ModelResponse](
			httpClient,
			baseURL+LLMServiceListModelsProcedure,
			connect.WithSchema(lLMServiceListModelsMethodDescriptor),
			connect.WithClientOptions(opts...),
		),
		listProviders: connect.NewClient[emptypb.Empty, llm.ProvidersResponse](
			httpClient,
			baseURL+LLMServiceListProvidersProcedure,
			connect.WithSchema(lLMServiceListProvidersMethodDescriptor),
			connect.WithClientOptions(opts...),
		),
		createProvider: connect.NewClient[llm.CreateProviderRequest, llm.CreateProviderResponse](
			httpClient,
			baseURL+LLMServiceCreateProviderProcedure,
			connect.WithSchema(lLMServiceCreateProviderMethodDescriptor),
			connect.WithClientOptions(opts...),
		),
		getProvider: connect.NewClient[llm.GetProviderRequest, llm.GetProviderResponse](
			httpClient,
			baseURL+LLMServiceGetProviderProcedure,
			connect.WithSchema(lLMServiceGetProviderMethodDescriptor),
			connect.WithClientOptions(opts...),
		),
		upsertProvider: connect.NewClient[llm.UpdateProviderRequest, llm.UpdateProviderResponse](
			httpClient,
			baseURL+LLMServiceUpsertProviderProcedure,
			connect.WithSchema(lLMServiceUpsertProviderMethodDescriptor),
			connect.WithClientOptions(opts...),
		),
		deleteProvider: connect.NewClient[llm.DeleteProviderRequest, emptypb.Empty](
			httpClient,
			baseURL+LLMServiceDeleteProviderProcedure,
			connect.WithSchema(lLMServiceDeleteProviderMethodDescriptor),
			connect.WithClientOptions(opts...),
		),
		getProviderConfig: connect.NewClient[llm.GetProviderConfigRequest, llm.GetProviderConfigResponse](
			httpClient,
			baseURL+LLMServiceGetProviderConfigProcedure,
			connect.WithSchema(lLMServiceGetProviderConfigMethodDescriptor),
			connect.WithClientOptions(opts...),
		),
		listTrackingLogs: connect.NewClient[emptypb.Empty, llm.LogResponse](
			httpClient,
			baseURL+LLMServiceListTrackingLogsProcedure,
			connect.WithSchema(lLMServiceListTrackingLogsMethodDescriptor),
			connect.WithClientOptions(opts...),
		),
	}
}

// lLMServiceClient implements LLMServiceClient.
type lLMServiceClient struct {
	chatCompletions       *connect.Client[llm.ChatCompletionRequest, llm.ChatCompletionResponse]
	streamChatCompletions *connect.Client[llm.ChatCompletionRequest, llm.ChatCompletionResponse]
	listModels            *connect.Client[llm.ModelRequest, llm.ModelResponse]
	listProviders         *connect.Client[emptypb.Empty, llm.ProvidersResponse]
	createProvider        *connect.Client[llm.CreateProviderRequest, llm.CreateProviderResponse]
	getProvider           *connect.Client[llm.GetProviderRequest, llm.GetProviderResponse]
	upsertProvider        *connect.Client[llm.UpdateProviderRequest, llm.UpdateProviderResponse]
	deleteProvider        *connect.Client[llm.DeleteProviderRequest, emptypb.Empty]
	getProviderConfig     *connect.Client[llm.GetProviderConfigRequest, llm.GetProviderConfigResponse]
	listTrackingLogs      *connect.Client[emptypb.Empty, llm.LogResponse]
}

// ChatCompletions calls llm.v1.LLMService.ChatCompletions.
func (c *lLMServiceClient) ChatCompletions(ctx context.Context, req *connect.Request[llm.ChatCompletionRequest]) (*connect.Response[llm.ChatCompletionResponse], error) {
	return c.chatCompletions.CallUnary(ctx, req)
}

// StreamChatCompletions calls llm.v1.LLMService.StreamChatCompletions.
func (c *lLMServiceClient) StreamChatCompletions(ctx context.Context, req *connect.Request[llm.ChatCompletionRequest]) (*connect.ServerStreamForClient[llm.ChatCompletionResponse], error) {
	return c.streamChatCompletions.CallServerStream(ctx, req)
}

// ListModels calls llm.v1.LLMService.ListModels.
func (c *lLMServiceClient) ListModels(ctx context.Context, req *connect.Request[llm.ModelRequest]) (*connect.Response[llm.ModelResponse], error) {
	return c.listModels.CallUnary(ctx, req)
}

// ListProviders calls llm.v1.LLMService.ListProviders.
func (c *lLMServiceClient) ListProviders(ctx context.Context, req *connect.Request[emptypb.Empty]) (*connect.Response[llm.ProvidersResponse], error) {
	return c.listProviders.CallUnary(ctx, req)
}

// CreateProvider calls llm.v1.LLMService.CreateProvider.
func (c *lLMServiceClient) CreateProvider(ctx context.Context, req *connect.Request[llm.CreateProviderRequest]) (*connect.Response[llm.CreateProviderResponse], error) {
	return c.createProvider.CallUnary(ctx, req)
}

// GetProvider calls llm.v1.LLMService.GetProvider.
func (c *lLMServiceClient) GetProvider(ctx context.Context, req *connect.Request[llm.GetProviderRequest]) (*connect.Response[llm.GetProviderResponse], error) {
	return c.getProvider.CallUnary(ctx, req)
}

// UpsertProvider calls llm.v1.LLMService.UpsertProvider.
func (c *lLMServiceClient) UpsertProvider(ctx context.Context, req *connect.Request[llm.UpdateProviderRequest]) (*connect.Response[llm.UpdateProviderResponse], error) {
	return c.upsertProvider.CallUnary(ctx, req)
}

// DeleteProvider calls llm.v1.LLMService.DeleteProvider.
func (c *lLMServiceClient) DeleteProvider(ctx context.Context, req *connect.Request[llm.DeleteProviderRequest]) (*connect.Response[emptypb.Empty], error) {
	return c.deleteProvider.CallUnary(ctx, req)
}

// GetProviderConfig calls llm.v1.LLMService.GetProviderConfig.
func (c *lLMServiceClient) GetProviderConfig(ctx context.Context, req *connect.Request[llm.GetProviderConfigRequest]) (*connect.Response[llm.GetProviderConfigResponse], error) {
	return c.getProviderConfig.CallUnary(ctx, req)
}

// ListTrackingLogs calls llm.v1.LLMService.ListTrackingLogs.
func (c *lLMServiceClient) ListTrackingLogs(ctx context.Context, req *connect.Request[emptypb.Empty]) (*connect.Response[llm.LogResponse], error) {
	return c.listTrackingLogs.CallUnary(ctx, req)
}

// LLMServiceHandler is an implementation of the llm.v1.LLMService service.
type LLMServiceHandler interface {
	ChatCompletions(context.Context, *connect.Request[llm.ChatCompletionRequest]) (*connect.Response[llm.ChatCompletionResponse], error)
	StreamChatCompletions(context.Context, *connect.Request[llm.ChatCompletionRequest], *connect.ServerStream[llm.ChatCompletionResponse]) error
	ListModels(context.Context, *connect.Request[llm.ModelRequest]) (*connect.Response[llm.ModelResponse], error)
	ListProviders(context.Context, *connect.Request[emptypb.Empty]) (*connect.Response[llm.ProvidersResponse], error)
	CreateProvider(context.Context, *connect.Request[llm.CreateProviderRequest]) (*connect.Response[llm.CreateProviderResponse], error)
	GetProvider(context.Context, *connect.Request[llm.GetProviderRequest]) (*connect.Response[llm.GetProviderResponse], error)
	UpsertProvider(context.Context, *connect.Request[llm.UpdateProviderRequest]) (*connect.Response[llm.UpdateProviderResponse], error)
	DeleteProvider(context.Context, *connect.Request[llm.DeleteProviderRequest]) (*connect.Response[emptypb.Empty], error)
	GetProviderConfig(context.Context, *connect.Request[llm.GetProviderConfigRequest]) (*connect.Response[llm.GetProviderConfigResponse], error)
	ListTrackingLogs(context.Context, *connect.Request[emptypb.Empty]) (*connect.Response[llm.LogResponse], error)
}

// NewLLMServiceHandler builds an HTTP handler from the service implementation. It returns the path
// on which to mount the handler and the handler itself.
//
// By default, handlers support the Connect, gRPC, and gRPC-Web protocols with the binary Protobuf
// and JSON codecs. They also support gzip compression.
func NewLLMServiceHandler(svc LLMServiceHandler, opts ...connect.HandlerOption) (string, http.Handler) {
	lLMServiceChatCompletionsHandler := connect.NewUnaryHandler(
		LLMServiceChatCompletionsProcedure,
		svc.ChatCompletions,
		connect.WithSchema(lLMServiceChatCompletionsMethodDescriptor),
		connect.WithHandlerOptions(opts...),
	)
	lLMServiceStreamChatCompletionsHandler := connect.NewServerStreamHandler(
		LLMServiceStreamChatCompletionsProcedure,
		svc.StreamChatCompletions,
		connect.WithSchema(lLMServiceStreamChatCompletionsMethodDescriptor),
		connect.WithHandlerOptions(opts...),
	)
	lLMServiceListModelsHandler := connect.NewUnaryHandler(
		LLMServiceListModelsProcedure,
		svc.ListModels,
		connect.WithSchema(lLMServiceListModelsMethodDescriptor),
		connect.WithHandlerOptions(opts...),
	)
	lLMServiceListProvidersHandler := connect.NewUnaryHandler(
		LLMServiceListProvidersProcedure,
		svc.ListProviders,
		connect.WithSchema(lLMServiceListProvidersMethodDescriptor),
		connect.WithHandlerOptions(opts...),
	)
	lLMServiceCreateProviderHandler := connect.NewUnaryHandler(
		LLMServiceCreateProviderProcedure,
		svc.CreateProvider,
		connect.WithSchema(lLMServiceCreateProviderMethodDescriptor),
		connect.WithHandlerOptions(opts...),
	)
	lLMServiceGetProviderHandler := connect.NewUnaryHandler(
		LLMServiceGetProviderProcedure,
		svc.GetProvider,
		connect.WithSchema(lLMServiceGetProviderMethodDescriptor),
		connect.WithHandlerOptions(opts...),
	)
	lLMServiceUpsertProviderHandler := connect.NewUnaryHandler(
		LLMServiceUpsertProviderProcedure,
		svc.UpsertProvider,
		connect.WithSchema(lLMServiceUpsertProviderMethodDescriptor),
		connect.WithHandlerOptions(opts...),
	)
	lLMServiceDeleteProviderHandler := connect.NewUnaryHandler(
		LLMServiceDeleteProviderProcedure,
		svc.DeleteProvider,
		connect.WithSchema(lLMServiceDeleteProviderMethodDescriptor),
		connect.WithHandlerOptions(opts...),
	)
	lLMServiceGetProviderConfigHandler := connect.NewUnaryHandler(
		LLMServiceGetProviderConfigProcedure,
		svc.GetProviderConfig,
		connect.WithSchema(lLMServiceGetProviderConfigMethodDescriptor),
		connect.WithHandlerOptions(opts...),
	)
	lLMServiceListTrackingLogsHandler := connect.NewUnaryHandler(
		LLMServiceListTrackingLogsProcedure,
		svc.ListTrackingLogs,
		connect.WithSchema(lLMServiceListTrackingLogsMethodDescriptor),
		connect.WithHandlerOptions(opts...),
	)
	return "/llm.v1.LLMService/", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		switch r.URL.Path {
		case LLMServiceChatCompletionsProcedure:
			lLMServiceChatCompletionsHandler.ServeHTTP(w, r)
		case LLMServiceStreamChatCompletionsProcedure:
			lLMServiceStreamChatCompletionsHandler.ServeHTTP(w, r)
		case LLMServiceListModelsProcedure:
			lLMServiceListModelsHandler.ServeHTTP(w, r)
		case LLMServiceListProvidersProcedure:
			lLMServiceListProvidersHandler.ServeHTTP(w, r)
		case LLMServiceCreateProviderProcedure:
			lLMServiceCreateProviderHandler.ServeHTTP(w, r)
		case LLMServiceGetProviderProcedure:
			lLMServiceGetProviderHandler.ServeHTTP(w, r)
		case LLMServiceUpsertProviderProcedure:
			lLMServiceUpsertProviderHandler.ServeHTTP(w, r)
		case LLMServiceDeleteProviderProcedure:
			lLMServiceDeleteProviderHandler.ServeHTTP(w, r)
		case LLMServiceGetProviderConfigProcedure:
			lLMServiceGetProviderConfigHandler.ServeHTTP(w, r)
		case LLMServiceListTrackingLogsProcedure:
			lLMServiceListTrackingLogsHandler.ServeHTTP(w, r)
		default:
			http.NotFound(w, r)
		}
	})
}

// UnimplementedLLMServiceHandler returns CodeUnimplemented from all methods.
type UnimplementedLLMServiceHandler struct{}

func (UnimplementedLLMServiceHandler) ChatCompletions(context.Context, *connect.Request[llm.ChatCompletionRequest]) (*connect.Response[llm.ChatCompletionResponse], error) {
	return nil, connect.NewError(connect.CodeUnimplemented, errors.New("llm.v1.LLMService.ChatCompletions is not implemented"))
}

func (UnimplementedLLMServiceHandler) StreamChatCompletions(context.Context, *connect.Request[llm.ChatCompletionRequest], *connect.ServerStream[llm.ChatCompletionResponse]) error {
	return connect.NewError(connect.CodeUnimplemented, errors.New("llm.v1.LLMService.StreamChatCompletions is not implemented"))
}

func (UnimplementedLLMServiceHandler) ListModels(context.Context, *connect.Request[llm.ModelRequest]) (*connect.Response[llm.ModelResponse], error) {
	return nil, connect.NewError(connect.CodeUnimplemented, errors.New("llm.v1.LLMService.ListModels is not implemented"))
}

func (UnimplementedLLMServiceHandler) ListProviders(context.Context, *connect.Request[emptypb.Empty]) (*connect.Response[llm.ProvidersResponse], error) {
	return nil, connect.NewError(connect.CodeUnimplemented, errors.New("llm.v1.LLMService.ListProviders is not implemented"))
}

func (UnimplementedLLMServiceHandler) CreateProvider(context.Context, *connect.Request[llm.CreateProviderRequest]) (*connect.Response[llm.CreateProviderResponse], error) {
	return nil, connect.NewError(connect.CodeUnimplemented, errors.New("llm.v1.LLMService.CreateProvider is not implemented"))
}

func (UnimplementedLLMServiceHandler) GetProvider(context.Context, *connect.Request[llm.GetProviderRequest]) (*connect.Response[llm.GetProviderResponse], error) {
	return nil, connect.NewError(connect.CodeUnimplemented, errors.New("llm.v1.LLMService.GetProvider is not implemented"))
}

func (UnimplementedLLMServiceHandler) UpsertProvider(context.Context, *connect.Request[llm.UpdateProviderRequest]) (*connect.Response[llm.UpdateProviderResponse], error) {
	return nil, connect.NewError(connect.CodeUnimplemented, errors.New("llm.v1.LLMService.UpsertProvider is not implemented"))
}

func (UnimplementedLLMServiceHandler) DeleteProvider(context.Context, *connect.Request[llm.DeleteProviderRequest]) (*connect.Response[emptypb.Empty], error) {
	return nil, connect.NewError(connect.CodeUnimplemented, errors.New("llm.v1.LLMService.DeleteProvider is not implemented"))
}

func (UnimplementedLLMServiceHandler) GetProviderConfig(context.Context, *connect.Request[llm.GetProviderConfigRequest]) (*connect.Response[llm.GetProviderConfigResponse], error) {
	return nil, connect.NewError(connect.CodeUnimplemented, errors.New("llm.v1.LLMService.GetProviderConfig is not implemented"))
}

func (UnimplementedLLMServiceHandler) ListTrackingLogs(context.Context, *connect.Request[emptypb.Empty]) (*connect.Response[llm.LogResponse], error) {
	return nil, connect.NewError(connect.CodeUnimplemented, errors.New("llm.v1.LLMService.ListTrackingLogs is not implemented"))
}
