syntax = "proto3";
package llm.v1;


service LLMService {
  rpc ChatCompletions(CompletionRequest) returns (CompletionResponse) {}
  rpc StreamChatCompletions(CompletionRequest) returns (stream CompletionResponse) {}
}

enum FinishReason {
  NULL = 0;
  LENGTH = 1;
  STOP = 2;
  ERROR = 3;
}

message Role {
  oneof role {
    string system = 1;
    string user = 2;
    string assistant = 3;
  }
}

message ChatMessage {
  // role of the message author. One of "system", "user", "assistant".
  Role role = 1;
  // content of the message
  string content = 2;
}

message TextCompletionParameters {
  // temperature of the sampling, between [0, 2]. default = 1.0
  optional float temperature = 1;
  
  // whether to stream partial completions back as they are generated. default = false
  optional bool stream = 2;
  optional uint32 top_k = 3;
  optional float top_p = 4;
  // number of chat completion choices to generate for each input message. default = 1
  optional uint32 n = 5;
  repeated string stop = 6;
  optional uint32 max_tokens = 7;
  optional float presence_penalty = 8;
  optional float frequency_penalty = 9;
}

message CompletionRequest {
  string model = 1;
  // a list of messages comprising all the conversation so far
  repeated ChatMessage messages = 2;
  optional TextCompletionParameters parameters = 3;
}

message CompletionChoice {
  // index of the choice in the list of choices.
  uint32 index = 1;
  // message generated by the model.
  repeated ChatMessage messages = 2;
  FinishReason finish_reason = 3;
}

message Usage {
  // number of tokens in the prompt.
  optional int32 prompt_tokens = 1;

  // number of tokens in the generated completion.
  optional int32 completion_tokens = 2;

  // total number of tokens used in the request (prompt + completion).
  optional int32 total_tokens = 3;
}

message CompletionResponse {
  // unique id for the chat completion.
  string id = 1;
  // object type, which is always "chat.completion[.chunk]".
  string object = 2;
  // unix timestamp (in seconds) of when the chat completion was created.
  uint64 created = 3;
  // model used for the completion
  string model = 4;
  // list of generated completion choices for the input prompt
  repeated CompletionChoice choices = 5;
  // usage statistics for the completion request.
  Usage usage = 6;
}
