// @generated by protoc-gen-es v1.6.0 with parameter "target=ts,import_extension="
// @generated from file llm/service.proto (package llm.v1beta1, syntax proto3)
/* eslint-disable */
// @ts-nocheck

import type { BinaryReadOptions, FieldList, JsonReadOptions, JsonValue, PartialMessage, PlainMessage } from "@bufbuild/protobuf";
import { Message, proto3 } from "@bufbuild/protobuf";

/**
 * @generated from enum llm.v1beta1.ModelTag
 */
export enum ModelTag {
  /**
   * @generated from enum value: MODEL_TYPE_UNKNOWN = 0;
   */
  MODEL_TYPE_UNKNOWN = 0,

  /**
   * @generated from enum value: GENERAL = 1;
   */
  GENERAL = 1,

  /**
   * @generated from enum value: CHAT = 2;
   */
  CHAT = 2,

  /**
   * @generated from enum value: TEXT = 3;
   */
  TEXT = 3,

  /**
   * @generated from enum value: CODE = 4;
   */
  CODE = 4,
}
// Retrieve enum metadata with: proto3.getEnumType(ModelTag)
proto3.util.setEnumType(ModelTag, "llm.v1beta1.ModelTag", [
  { no: 0, name: "MODEL_TYPE_UNKNOWN" },
  { no: 1, name: "GENERAL" },
  { no: 2, name: "CHAT" },
  { no: 3, name: "TEXT" },
  { no: 4, name: "CODE" },
]);

/**
 * @generated from enum llm.v1beta1.Status
 */
export enum Status {
  /**
   * @generated from enum value: STATUS_UNKNOWN = 0;
   */
  STATUS_UNKNOWN = 0,

  /**
   * @generated from enum value: INITLIZING = 1;
   */
  INITLIZING = 1,

  /**
   * @generated from enum value: READY = 2;
   */
  READY = 2,

  /**
   * @generated from enum value: ERROR = 3;
   */
  ERROR = 3,
}
// Retrieve enum metadata with: proto3.getEnumType(Status)
proto3.util.setEnumType(Status, "llm.v1beta1.Status", [
  { no: 0, name: "STATUS_UNKNOWN" },
  { no: 1, name: "INITLIZING" },
  { no: 2, name: "READY" },
  { no: 3, name: "ERROR" },
]);

/**
 * @generated from enum llm.v1beta1.Role
 */
export enum Role {
  /**
   * @generated from enum value: ROLE_UNKNOWN = 0;
   */
  ROLE_UNKNOWN = 0,

  /**
   * @generated from enum value: SYSTEM = 1;
   */
  SYSTEM = 1,

  /**
   * @generated from enum value: USER = 2;
   */
  USER = 2,

  /**
   * @generated from enum value: ASSISTANT = 3;
   */
  ASSISTANT = 3,
}
// Retrieve enum metadata with: proto3.getEnumType(Role)
proto3.util.setEnumType(Role, "llm.v1beta1.Role", [
  { no: 0, name: "ROLE_UNKNOWN" },
  { no: 1, name: "SYSTEM" },
  { no: 2, name: "USER" },
  { no: 3, name: "ASSISTANT" },
]);

/**
 * @generated from message llm.v1beta1.AvaliableModel
 */
export class AvaliableModel extends Message<AvaliableModel> {
  /**
   * @generated from field: repeated llm.v1beta1.ModelTag model_tagas = 1;
   */
  modelTagas: ModelTag[] = [];

  /**
   * @generated from field: uint32 model_id = 2;
   */
  modelId = 0;

  /**
   * @generated from field: string model_name = 3;
   */
  modelName = "";

  /**
   * @generated from field: string size = 4;
   */
  size = "";

  /**
   * @generated from field: string model_description = 5;
   */
  modelDescription = "";

  constructor(data?: PartialMessage<AvaliableModel>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "llm.v1beta1.AvaliableModel";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "model_tagas", kind: "enum", T: proto3.getEnumType(ModelTag), repeated: true },
    { no: 2, name: "model_id", kind: "scalar", T: 13 /* ScalarType.UINT32 */ },
    { no: 3, name: "model_name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 4, name: "size", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 5, name: "model_description", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): AvaliableModel {
    return new AvaliableModel().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): AvaliableModel {
    return new AvaliableModel().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): AvaliableModel {
    return new AvaliableModel().fromJsonString(jsonString, options);
  }

  static equals(a: AvaliableModel | PlainMessage<AvaliableModel> | undefined, b: AvaliableModel | PlainMessage<AvaliableModel> | undefined): boolean {
    return proto3.util.equals(AvaliableModel, a, b);
  }
}

/**
 * @generated from message llm.v1beta1.LoadModelRequest
 */
export class LoadModelRequest extends Message<LoadModelRequest> {
  /**
   * @generated from field: uint32 model_id = 1;
   */
  modelId = 0;

  /**
   * @generated from field: string json_model_param = 999;
   */
  jsonModelParam = "";

  constructor(data?: PartialMessage<LoadModelRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "llm.v1beta1.LoadModelRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "model_id", kind: "scalar", T: 13 /* ScalarType.UINT32 */ },
    { no: 999, name: "json_model_param", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): LoadModelRequest {
    return new LoadModelRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): LoadModelRequest {
    return new LoadModelRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): LoadModelRequest {
    return new LoadModelRequest().fromJsonString(jsonString, options);
  }

  static equals(a: LoadModelRequest | PlainMessage<LoadModelRequest> | undefined, b: LoadModelRequest | PlainMessage<LoadModelRequest> | undefined): boolean {
    return proto3.util.equals(LoadModelRequest, a, b);
  }
}

/**
 * @generated from message llm.v1beta1.LoadModelResponse
 */
export class LoadModelResponse extends Message<LoadModelResponse> {
  /**
   * @generated from field: llm.v1beta1.Status current_status = 1;
   */
  currentStatus = Status.STATUS_UNKNOWN;

  /**
   * @generated from field: llm.v1beta1.AvaliableModel current_model = 2;
   */
  currentModel?: AvaliableModel;

  constructor(data?: PartialMessage<LoadModelResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "llm.v1beta1.LoadModelResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "current_status", kind: "enum", T: proto3.getEnumType(Status) },
    { no: 2, name: "current_model", kind: "message", T: AvaliableModel },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): LoadModelResponse {
    return new LoadModelResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): LoadModelResponse {
    return new LoadModelResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): LoadModelResponse {
    return new LoadModelResponse().fromJsonString(jsonString, options);
  }

  static equals(a: LoadModelResponse | PlainMessage<LoadModelResponse> | undefined, b: LoadModelResponse | PlainMessage<LoadModelResponse> | undefined): boolean {
    return proto3.util.equals(LoadModelResponse, a, b);
  }
}

/**
 * @generated from message llm.v1beta1.InferenceArgs
 */
export class InferenceArgs extends Message<InferenceArgs> {
  /**
   * @generated from field: float temperature = 1;
   */
  temperature = 0;

  /**
   * @generated from field: float top_p = 2;
   */
  topP = 0;

  /**
   * @generated from field: uint32 max_gen_len = 3;
   */
  maxGenLen = 0;

  /**
   * @generated from field: uint32 repetition_penalty = 4;
   */
  repetitionPenalty = 0;

  /**
   * A json string for extra args, will merge into inference args
   * Map's value is not dynamic type, so we use json string
   *
   * @generated from field: string json_extra_args = 999;
   */
  jsonExtraArgs = "";

  constructor(data?: PartialMessage<InferenceArgs>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "llm.v1beta1.InferenceArgs";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "temperature", kind: "scalar", T: 2 /* ScalarType.FLOAT */ },
    { no: 2, name: "top_p", kind: "scalar", T: 2 /* ScalarType.FLOAT */ },
    { no: 3, name: "max_gen_len", kind: "scalar", T: 13 /* ScalarType.UINT32 */ },
    { no: 4, name: "repetition_penalty", kind: "scalar", T: 13 /* ScalarType.UINT32 */ },
    { no: 999, name: "json_extra_args", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): InferenceArgs {
    return new InferenceArgs().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): InferenceArgs {
    return new InferenceArgs().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): InferenceArgs {
    return new InferenceArgs().fromJsonString(jsonString, options);
  }

  static equals(a: InferenceArgs | PlainMessage<InferenceArgs> | undefined, b: InferenceArgs | PlainMessage<InferenceArgs> | undefined): boolean {
    return proto3.util.equals(InferenceArgs, a, b);
  }
}

/**
 * @generated from message llm.v1beta1.CompletionRequest
 */
export class CompletionRequest extends Message<CompletionRequest> {
  /**
   * @generated from field: string request_id = 1;
   */
  requestId = "";

  /**
   * @generated from field: string prompt = 2;
   */
  prompt = "";

  /**
   * @generated from field: llm.v1beta1.InferenceArgs inference_args = 3;
   */
  inferenceArgs?: InferenceArgs;

  constructor(data?: PartialMessage<CompletionRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "llm.v1beta1.CompletionRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "request_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "prompt", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "inference_args", kind: "message", T: InferenceArgs },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): CompletionRequest {
    return new CompletionRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): CompletionRequest {
    return new CompletionRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): CompletionRequest {
    return new CompletionRequest().fromJsonString(jsonString, options);
  }

  static equals(a: CompletionRequest | PlainMessage<CompletionRequest> | undefined, b: CompletionRequest | PlainMessage<CompletionRequest> | undefined): boolean {
    return proto3.util.equals(CompletionRequest, a, b);
  }
}

/**
 * @generated from message llm.v1beta1.CompletionPrediction
 */
export class CompletionPrediction extends Message<CompletionPrediction> {
  /**
   * @generated from field: string request_id = 1;
   */
  requestId = "";

  /**
   * @generated from field: string response_id = 2;
   */
  responseId = "";

  /**
   * @generated from field: string generation = 3;
   */
  generation = "";

  constructor(data?: PartialMessage<CompletionPrediction>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "llm.v1beta1.CompletionPrediction";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "request_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "response_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "generation", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): CompletionPrediction {
    return new CompletionPrediction().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): CompletionPrediction {
    return new CompletionPrediction().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): CompletionPrediction {
    return new CompletionPrediction().fromJsonString(jsonString, options);
  }

  static equals(a: CompletionPrediction | PlainMessage<CompletionPrediction> | undefined, b: CompletionPrediction | PlainMessage<CompletionPrediction> | undefined): boolean {
    return proto3.util.equals(CompletionPrediction, a, b);
  }
}

/**
 * @generated from message llm.v1beta1.ChatMessage
 */
export class ChatMessage extends Message<ChatMessage> {
  /**
   * @generated from field: llm.v1beta1.Role role = 1;
   */
  role = Role.ROLE_UNKNOWN;

  /**
   * @generated from field: string content = 2;
   */
  content = "";

  constructor(data?: PartialMessage<ChatMessage>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "llm.v1beta1.ChatMessage";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "role", kind: "enum", T: proto3.getEnumType(Role) },
    { no: 2, name: "content", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ChatMessage {
    return new ChatMessage().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ChatMessage {
    return new ChatMessage().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ChatMessage {
    return new ChatMessage().fromJsonString(jsonString, options);
  }

  static equals(a: ChatMessage | PlainMessage<ChatMessage> | undefined, b: ChatMessage | PlainMessage<ChatMessage> | undefined): boolean {
    return proto3.util.equals(ChatMessage, a, b);
  }
}

/**
 * @generated from message llm.v1beta1.ChatRequest
 */
export class ChatRequest extends Message<ChatRequest> {
  /**
   * @generated from field: string request_id = 1;
   */
  requestId = "";

  /**
   * @generated from field: repeated llm.v1beta1.ChatMessage messages = 2;
   */
  messages: ChatMessage[] = [];

  /**
   * @generated from field: llm.v1beta1.InferenceArgs inference_args = 3;
   */
  inferenceArgs?: InferenceArgs;

  constructor(data?: PartialMessage<ChatRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "llm.v1beta1.ChatRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "request_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "messages", kind: "message", T: ChatMessage, repeated: true },
    { no: 3, name: "inference_args", kind: "message", T: InferenceArgs },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ChatRequest {
    return new ChatRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ChatRequest {
    return new ChatRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ChatRequest {
    return new ChatRequest().fromJsonString(jsonString, options);
  }

  static equals(a: ChatRequest | PlainMessage<ChatRequest> | undefined, b: ChatRequest | PlainMessage<ChatRequest> | undefined): boolean {
    return proto3.util.equals(ChatRequest, a, b);
  }
}

/**
 * @generated from message llm.v1beta1.ChatPrediction
 */
export class ChatPrediction extends Message<ChatPrediction> {
  /**
   * @generated from field: string request_id = 1;
   */
  requestId = "";

  /**
   * @generated from field: string response_id = 2;
   */
  responseId = "";

  /**
   * @generated from field: llm.v1beta1.ChatMessage message = 3;
   */
  message?: ChatMessage;

  constructor(data?: PartialMessage<ChatPrediction>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "llm.v1beta1.ChatPrediction";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "request_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "response_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "message", kind: "message", T: ChatMessage },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ChatPrediction {
    return new ChatPrediction().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ChatPrediction {
    return new ChatPrediction().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ChatPrediction {
    return new ChatPrediction().fromJsonString(jsonString, options);
  }

  static equals(a: ChatPrediction | PlainMessage<ChatPrediction> | undefined, b: ChatPrediction | PlainMessage<ChatPrediction> | undefined): boolean {
    return proto3.util.equals(ChatPrediction, a, b);
  }
}

